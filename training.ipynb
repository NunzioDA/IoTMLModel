{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ObjectDetectionCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ObjectDetectionCNN, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Pooling layer\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(128 * 26 * 19, 256)  # Assuming input image size of 32x32\n",
    "        self.fc2 = nn.Linear(256, 1)\n",
    "        \n",
    "        # Activation functions\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        \n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca 1, Loss Addestramento: 0.6874504089355469\n",
      "Accuratezza Validazione: 83.33%\n",
      "Epoca 2, Loss Addestramento: 0.6425769925117493\n",
      "Accuratezza Validazione: 16.67%\n",
      "Epoca 3, Loss Addestramento: 0.7270681262016296\n",
      "Accuratezza Validazione: 100.00%\n",
      "Epoca 4, Loss Addestramento: 0.34211012721061707\n",
      "Accuratezza Validazione: 100.00%\n",
      "Epoca 5, Loss Addestramento: 0.14339560270309448\n",
      "Accuratezza Validazione: 100.00%\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, target1_dir, target0_dir, transform=None):\n",
    "        \"\"\"\n",
    "        target1_dir: directory con le immagini per target=1\n",
    "        target0_dir: directory con le immagini per target=0\n",
    "        \"\"\"\n",
    "        self.target1_images = [os.path.join(target1_dir, f) for f in os.listdir(target1_dir)]\n",
    "        self.target0_images = [os.path.join(target0_dir, f) for f in os.listdir(target0_dir)]\n",
    "        self.images = self.target1_images + self.target0_images\n",
    "        self.labels = [1] * len(self.target1_images) + [0] * len(self.target0_images)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.images[idx]\n",
    "        image = Image.open(image_path).convert(\"RGB\")  # Carica l'immagine e la converte in RGB\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Definisci le trasformazioni\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Converte l'immagine in tensore\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalizzazione\n",
    "])\n",
    "\n",
    "# Cartelle che contengono le immagini\n",
    "target1_dir = './data/target1/'  # Sostituisci con il percorso della cartella target1\n",
    "target0_dir = './data/target0/'  # Sostituisci con il percorso della cartella target0\n",
    "\n",
    "# Creare il dataset personalizzato\n",
    "dataset = CustomDataset(target1_dir, target0_dir, transform=transform)\n",
    "\n",
    "# Separare il dataset in addestramento (80%) e validazione (20%)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Creare DataLoader per il training e la validazione\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Inizializzare il modello\n",
    "model = ObjectDetectionCNN()\n",
    "\n",
    "# Impostare la funzione di perdita e l'ottimizzatore\n",
    "criterion = torch.nn.BCELoss()  # Binary Cross Entropy per un problema di classificazione binaria\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Funzione di addestramento\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=5):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.squeeze(), labels.float())  # Etichette in formato float per BCELoss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f'Epoca {epoch+1}, Loss Addestramento: {running_loss / len(train_loader)}')\n",
    "\n",
    "        # Valutazione del modello sui dati di validazione\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                outputs = model(inputs)\n",
    "                predicted = (outputs.squeeze() > 0.5).float()  # Usa la soglia 0.5 per classificare\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = correct / total\n",
    "        print(f'Accuratezza Validazione: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Addestrare il modello\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ski",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
